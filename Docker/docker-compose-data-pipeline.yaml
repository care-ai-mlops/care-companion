name: data-pipeline

services:
  data-pipeline:
    build:
      context: ..
      dockerfile: Docker/Dockerfile
    container_name: data-pipeline
    volumes:
      - ${HOME}/care-companion/:/workspace             
      - /mnt/object:/mnt/object    # Mount host object storage path
      - /mnt/block:/mnt/block      # Mount block storage for outputs
    working_dir: /workspace
    command: >
      python3 src/run_data_pipeline.py
      --minio-endpoint ${MINIO_ENDPOINT}
      --minio-access-key ${MINIO_ACCESS_KEY}
      --minio-secret-key ${MINIO_SECRET_KEY}
      --minio-bucket ${MINIO_BUCKET}
      --mlflow-tracking-uri ${MLFLOW_TRACKING_URI}
      --data-dir /mnt/block/training_data
      --batch-size 1000
      --retrain-interval 24
      --validation-threshold 0.8
    environment:
      - MINIO_ENDPOINT=${KVM_FLOATING_IP}:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - MINIO_BUCKET=mlflow-artifacts
      - MLFLOW_TRACKING_URI=http://${KVM_FLOATING_IP}:8000
    restart: unless-stopped 